import pandas as pd
import json
import random
from collections import defaultdict

# ================= C·∫§U H√åNH LOGIC =================
# 1. S·ªë l∆∞·ª£ng t√≠nh c√°ch m·ªói ng∆∞·ªùi s·∫Ω c√≥
NUM_TRAITS_PER_USER = 10 

# 2. Ng∆∞·ª°ng ƒë·ªÉ k·∫øt b·∫°n (Chung √≠t nh·∫•t bao nhi√™u t√≠nh c√°ch th√¨ n·ªëi?)
# B·∫°n y√™u c·∫ßu 3-4 ho·∫∑c 5. T√¥i ƒë·ªÉ m·∫∑c ƒë·ªãnh l√† 4 (kh√° kh√≥, t·∫°o nh√≥m r·∫•t ch·∫•t l∆∞·ª£ng)
MIN_SHARED_TRAITS = 4

# 3. KHO T√çNH C√ÅCH (POOL) - Kho·∫£ng 50 c√°i ƒë·ªÉ random cho ƒëa d·∫°ng
TRAIT_POOL = [
    # T√≠nh c√°ch
    "H√†i h∆∞·ªõc", "Tr·∫ßm t√≠nh", "H∆∞·ªõng n·ªôi", "H∆∞·ªõng ngo·∫°i", "Th·∫≥ng th·∫Øn", "Nh·∫°y c·∫£m", 
    "L√£ng m·∫°n", "Th·ª±c t·∫ø", "K·ªπ t√≠nh", "H√≤a ƒë·ªìng", "S√°ng t·∫°o", "L·∫°nh l√πng",
    # S·ªü th√≠ch
    "Th√≠ch Code", "Th√≠ch Game", "M√™ Anime", "Y√™u M√®o", "Y√™u Ch√≥", "Th√≠ch Gym",
    "B√≥ng ƒë√°", "C·∫ßu l√¥ng", "B∆°i l·ªôi", "Ch·∫°y b·ªô", "Leo n√∫i", "ƒê·∫°p xe",
    # ƒÇn u·ªëng
    "Nghi·ªán Tr√† s·ªØa", "M√™ C√† ph√™", "Team B√∫n ƒë·∫≠u", "Team Ph·ªü", "Th√≠ch ƒê·ªì n∆∞·ªõng", 
    "ƒÇn chay", "Th√≠ch ƒê·ªì ng·ªçt", "Gh√©t H√†nh",
    # Ngh·ªá thu·∫≠t / Gi·∫£i tr√≠
    "Nh·∫°c Pop", "Nh·∫°c Rock", "Nh·∫°c Indie", "Th√≠ch Rap", "Nh·∫°c Bolero",
    "Th√≠ch Du l·ªãch", "Th√≠ch Ng·ªß", "M·ªçt s√°ch", "Xem phim H√†n", "H√≥ng drama",
    "Ch·ª•p ·∫£nh", "V·∫Ω tranh", "N·∫•u ƒÉn",
    # C√¥ng ngh·ªá / Kh√°c
    "D√πng iPhone", "D√πng Android", "Team Windows", "Team Mac", "Th√≠ch AI",
    "Th√≠ch Ch·ª©ng kho√°n", "Th√≠ch Ti·ªÅn ·∫£o"
]
# ===================================================

def _read_users_csv(path='users.csv'):
    """ƒê·ªçc CSV v·ªõi logging r√µ r√†ng khi ph·∫£i fallback encoding."""
    try:
        df = pd.read_csv(path, skipinitialspace=True, encoding='utf-8-sig')
        print("‚úÖ ƒê·ªçc CSV b·∫±ng UTF-8 th√†nh c√¥ng.")
        return df
    except UnicodeError:
        print("‚ö†Ô∏è UTF-8 th·∫•t b·∫°i, th·ª≠ ƒë·ªçc b·∫±ng UTF-16...")
        df = pd.read_csv(path, skipinitialspace=True, encoding='utf-16')
        print("‚úÖ ƒê·ªçc CSV b·∫±ng UTF-16 th√†nh c√¥ng.")
        return df


def _validate_users_df(df: pd.DataFrame) -> pd.DataFrame:
    required_columns = {'id', 'name'}
    missing = required_columns - set(df.columns.str.lower())
    if missing:
        raise ValueError(f"Thi·∫øu c·ªôt b·∫Øt bu·ªôc trong users.csv: {', '.join(missing)}")

    normalized = {col: col.lower() for col in df.columns}
    df = df.rename(columns=normalized)

    has_sex = 'sex' in df.columns
    has_group = 'group' in df.columns
    if not has_sex and not has_group:
        raise ValueError("C·∫ßn c√≥ ch√≠ √≠t m·ªôt c·ªôt 'sex' ho·∫∑c 'group'.")

    # Chu·∫©n h√≥a t√™n c·ªôt v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ tr√°nh l·ªói vi·∫øt hoa/th∆∞·ªùng.
    if df['id'].isnull().any():
        raise ValueError("C·ªôt 'id' kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")

    df['id'] = df['id'].astype(int)
    if df['id'].duplicated().any():
        dup_ids = df.loc[df['id'].duplicated(), 'id'].tolist()
        raise ValueError(f"ID b·ªã tr√πng l·∫∑p: {dup_ids}")

    df['name'] = df['name'].fillna('').astype(str).str.strip()
    if has_sex:
        df['sex'] = df['sex'].fillna('Unknown').astype(str)
    if has_group:
        df['group'] = df['group'].fillna('Unknown').astype(str)

    return df


def _extract_traits_from_df(df: pd.DataFrame) -> pd.DataFrame:
    """Tr√≠ch xu·∫•t traits t·ª´ CSV n·∫øu c√≥, ng∆∞·ª£c l·∫°i random nh∆∞ c≈©."""
    # T√¨m c√°c c·ªôt trait (trait1, trait2, ... ho·∫∑c b·∫Øt ƒë·∫ßu b·∫±ng 'trait')
    trait_columns = [col for col in df.columns if col.lower().startswith('trait')]
    
    if len(trait_columns) >= 10:
        # CSV c√≥ s·∫µn traits - s·ª≠ d·ª•ng ch√∫ng
        print(f"‚úÖ Ph√°t hi·ªán {len(trait_columns)} c·ªôt traits trong CSV, s·ª≠ d·ª•ng d·ªØ li·ªáu c√≥ s·∫µn.")
        
        # T·∫°o c·ªôt 'traits' t·ª´ c√°c c·ªôt trait
        def extract_row_traits(row):
            traits = []
            for col in trait_columns[:10]:  # L·∫•y t·ªëi ƒëa 10 traits ƒë·∫ßu
                trait = str(row[col]).strip()
                if trait and trait.lower() != 'nan':
                    traits.append(trait)
            return traits
        
        df['traits'] = df.apply(extract_row_traits, axis=1)
        
        # Ki·ªÉm tra v√† log
        empty_traits = df['traits'].apply(len) == 0
        if empty_traits.any():
            print(f"‚ö†Ô∏è C·∫£nh b√°o: {empty_traits.sum()} ng∆∞·ªùi kh√¥ng c√≥ traits.")
            
    else:
        # CSV kh√¥ng c√≥ traits - random nh∆∞ c≈©
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ƒë·ªß 10 c·ªôt traits trong CSV. S·∫Ω random {NUM_TRAITS_PER_USER} traits cho m·ªói ng∆∞·ªùi.")
        df['traits'] = df['id'].apply(_deterministic_traits)
    
    return df


def _deterministic_traits(user_id: int) -> list:
    """Sinh danh s√°ch traits c·ªë ƒë·ªãnh d·ª±a tr√™n user_id ƒë·ªÉ d·ªÖ t√°i l·∫≠p k·∫øt qu·∫£."""
    rng = random.Random(user_id)
    return rng.sample(TRAIT_POOL, NUM_TRAITS_PER_USER)


def create_json_advanced():
    try:
        df = _read_users_csv()
        df = _validate_users_df(df)
        df = _extract_traits_from_df(df)  # Tr√≠ch xu·∫•t traits t·ª´ CSV ho·∫∑c random
        print(f"--- ƒê√£ ƒë·ªçc {len(df)} users h·ª£p l·ªá t·ª´ file CSV ---")

        nodes = []

        for _, row in df.iterrows():
            user_id = int(row['id'])
            user_name = row['name'] or f"User {user_id}"
            sex = row.get('sex') or row.get('group') or 'Unknown'

            # S·ª≠ d·ª•ng traits ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
            my_traits = row['traits']
            display_traits = ", ".join(my_traits)
            image_url = f"https://i.pravatar.cc/150?u={user_id}"

            node = {
                "id": user_id,
                "label": str(user_name),
                "sex": str(sex),
                "image": image_url,
                "shape": "circularImage",
                "traits": my_traits,
                "display_traits": display_traits,
                "title": f"T√™n: {user_name}\nGi·ªõi t√≠nh: {sex}\n\nS·ªü th√≠ch:\n- " + "\n- ".join(my_traits),
                "value": 20
            }
            nodes.append(node)

        print(f"--- ƒêang so kh·ªõp (M·ªói ng∆∞·ªùi {NUM_TRAITS_PER_USER} t√≠nh c√°ch, c·∫ßn tr√πng >= {MIN_SHARED_TRAITS}) ---")

        trait_to_users = defaultdict(list)
        shared_traits = defaultdict(set)

        for node in nodes:
            user_id = node['id']
            for trait in node['traits']:
                for other_id in trait_to_users[trait]:
                    key = tuple(sorted((user_id, other_id)))
                    shared_traits[key].add(trait)
                trait_to_users[trait].append(user_id)

        edges = []
        for (user_a, user_b), traits in shared_traits.items():
            if len(traits) >= MIN_SHARED_TRAITS:
                trait_list = ', '.join(sorted(traits))
                edges.append({
                    "from": user_a,
                    "to": user_b,
                    "title": f"Chung {len(traits)} ƒëi·ªÉm: {trait_list}"
                })

        final_data = {"nodes": nodes, "edges": edges}
        with open('data.json', 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=4)

        print("------------------------------------------------")
        print(f"‚úÖ XONG! ƒê√£ t·∫°o {len(edges)} k·∫øt n·ªëi.")
        if nodes:
            avg_friends = round(len(edges) * 2 / len(nodes), 1)
            print(f"üìä Trung b√¨nh m·ªói ng∆∞·ªùi c√≥: {avg_friends} b·∫°n b√®.")
        if not edges:
            print("‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng c√≥ k·∫øt n·ªëi n√†o! H√£y gi·∫£m 'MIN_SHARED_TRAITS' xu·ªëng 3.")

    except Exception as e:
        print(f"‚ùå L·ªói: {e}")


if __name__ == "__main__":
    create_json_advanced()